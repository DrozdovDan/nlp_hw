{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sVGBTApqf0d0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEZ0ffOff0d2"
   },
   "source": [
    "### Загрузить датасет [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5PYNlYm0f0d5",
    "outputId": "ab2a7207-8698-4385-c611-0a9ba535e8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-31 18:40:35--  https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\n",
      "162.125.70.18, 2620:100:6026:18::a27d:4612)... \n",
      "connected. to www.dropbox.com (www.dropbox.com)|162.125.70.18|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.dropbox.com/scl/fi/0mulrothty5o8i8ud9gz2/arxivData.json.tar.gz?rlkey=n759u5qx2xpxxglmrl390vwvk&dl=1 [following]\n",
      "--2025-03-31 18:40:36--  https://www.dropbox.com/scl/fi/0mulrothty5o8i8ud9gz2/arxivData.json.tar.gz?rlkey=n759u5qx2xpxxglmrl390vwvk&dl=1\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "302 Foundest sent, awaiting response... \n",
      "Location: https://uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com/cd/0/inline/Cm76fy8MsTJKkwVPj2e4lsgGkUmhCDbyhZxzj4vAuNo1VRH-P5zEYUEDSFMuQZqp-R9yA8ztNh7pBfHQVLiwWa2rvg0zB8knFFo7wfN3AzfYm1LbqSzT5iwU2p7XQ-OdVEQ/file?dl=1# [following]\n",
      "--2025-03-31 18:40:36--  https://uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com/cd/0/inline/Cm76fy8MsTJKkwVPj2e4lsgGkUmhCDbyhZxzj4vAuNo1VRH-P5zEYUEDSFMuQZqp-R9yA8ztNh7pBfHQVLiwWa2rvg0zB8knFFo7wfN3AzfYm1LbqSzT5iwU2p7XQ-OdVEQ/file?dl=1\n",
      "162.125.70.15, 2620:100:6026:15::a27d:460fdropboxusercontent.com (uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com)... \n",
      "Connecting to uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com (uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com)|162.125.70.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/Cm4YZZuIZKDCGWLkQG2SgnQyIAYx0oiqKeGzaoMK8Vroj8TVfnA67FTl_7r9yg57lDZ_kBJfG2ZUBkztOAjmTIjeD2xH9rm4HofHkFDrQd5JdE2QecwnjQN7Vi_XW_CVsbxpQDGqzJ_RDueZ2SK3zTc5ugPKAUJTU6_ccCMU5NDMcYwPeVQjmm_tSTkQ_UG4r9r5ISWVGo-MNuPCtY_v0TZUSqbS6ntGArYxtpLv-DiWCJTrtbAqUaz7FTmyPKw0C4Y3cmc_9FSSfFvGGeYDipf30lBiShQGHVehBKjFKowDHplqa3VrCeJ2CYPDrdT4pu919Z5qrKcDuX1zD476tjmmcOupZ23ODtV5oZC1dZBjaw/file?dl=1 [following]\n",
      "--2025-03-31 18:40:37--  https://uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com/cd/0/inline2/Cm4YZZuIZKDCGWLkQG2SgnQyIAYx0oiqKeGzaoMK8Vroj8TVfnA67FTl_7r9yg57lDZ_kBJfG2ZUBkztOAjmTIjeD2xH9rm4HofHkFDrQd5JdE2QecwnjQN7Vi_XW_CVsbxpQDGqzJ_RDueZ2SK3zTc5ugPKAUJTU6_ccCMU5NDMcYwPeVQjmm_tSTkQ_UG4r9r5ISWVGo-MNuPCtY_v0TZUSqbS6ntGArYxtpLv-DiWCJTrtbAqUaz7FTmyPKw0C4Y3cmc_9FSSfFvGGeYDipf30lBiShQGHVehBKjFKowDHplqa3VrCeJ2CYPDrdT4pu919Z5qrKcDuX1zD476tjmmcOupZ23ODtV5oZC1dZBjaw/file?dl=1\n",
      "Reusing existing connection to uc2226620dcc83aa488f37cf08d3.dl.dropboxusercontent.com:443.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 18933283 (18M) [application/binary]\n",
      "Saving to: ‘arxivData.json.tar.gz’\n",
      "\n",
      "arxivData.json.tar. 100%[===================>]  18.06M  10.0MB/s    in 1.8s    \n",
      "\n",
      "2025-03-31 18:40:40 (10.0 MB/s) - ‘arxivData.json.tar.gz’ saved [18933283/18933283]\n",
      "\n",
      "arxivData.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>month</th>\n",
       "      <th>summary</th>\n",
       "      <th>tag</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16830</th>\n",
       "      <td>[{'name': 'John J. Camilleri'}, {'name': 'Norm...</td>\n",
       "      <td>15</td>\n",
       "      <td>1706.04997v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>We are concerned with the analysis of normativ...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Extracting Formal Models from Normative Texts</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31463</th>\n",
       "      <td>[{'name': 'Xiao Song'}, {'name': 'Xu Zhao'}, {...</td>\n",
       "      <td>13</td>\n",
       "      <td>1803.04722v1</td>\n",
       "      <td>[{'rel': 'related', 'href': 'http://dx.doi.org...</td>\n",
       "      <td>3</td>\n",
       "      <td>Robust features are of vital importance to fac...</td>\n",
       "      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Face Spoofing Detection by Fusing Binocular De...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9017</th>\n",
       "      <td>[{'name': 'Alexander Herzog'}, {'name': 'Slava...</td>\n",
       "      <td>15</td>\n",
       "      <td>1708.04557v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>8</td>\n",
       "      <td>We present a database of parliamentary debates...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Database of Parliamentary Speeches in Ireland,...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38390</th>\n",
       "      <td>[{'name': 'Rishab Nithyanand'}, {'name': 'Bria...</td>\n",
       "      <td>6</td>\n",
       "      <td>1706.01875v2</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>6</td>\n",
       "      <td>The Internet and online forums such as Reddit ...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Measuring Offensive Speech in Online Political...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>[{'name': 'Tatjana Pavlenko'}, {'name': 'Dietr...</td>\n",
       "      <td>12</td>\n",
       "      <td>1301.0593v1</td>\n",
       "      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n",
       "      <td>12</td>\n",
       "      <td>We present a growing dimension asymptotic form...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "      <td>Bayesian Network Classifiers in a High Dimensi...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  author  day            id  \\\n",
       "16830  [{'name': 'John J. Camilleri'}, {'name': 'Norm...   15  1706.04997v1   \n",
       "31463  [{'name': 'Xiao Song'}, {'name': 'Xu Zhao'}, {...   13  1803.04722v1   \n",
       "9017   [{'name': 'Alexander Herzog'}, {'name': 'Slava...   15  1708.04557v1   \n",
       "38390  [{'name': 'Rishab Nithyanand'}, {'name': 'Bria...    6  1706.01875v2   \n",
       "5301   [{'name': 'Tatjana Pavlenko'}, {'name': 'Dietr...   12   1301.0593v1   \n",
       "\n",
       "                                                    link  month  \\\n",
       "16830  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n",
       "31463  [{'rel': 'related', 'href': 'http://dx.doi.org...      3   \n",
       "9017   [{'rel': 'alternate', 'href': 'http://arxiv.or...      8   \n",
       "38390  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n",
       "5301   [{'rel': 'alternate', 'href': 'http://arxiv.or...     12   \n",
       "\n",
       "                                                 summary  \\\n",
       "16830  We are concerned with the analysis of normativ...   \n",
       "31463  Robust features are of vital importance to fac...   \n",
       "9017   We present a database of parliamentary debates...   \n",
       "38390  The Internet and online forums such as Reddit ...   \n",
       "5301   We present a growing dimension asymptotic form...   \n",
       "\n",
       "                                                     tag  \\\n",
       "16830  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "31463  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n",
       "9017   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "38390  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...   \n",
       "5301   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n",
       "\n",
       "                                                   title  year  \n",
       "16830      Extracting Formal Models from Normative Texts  2017  \n",
       "31463  Face Spoofing Detection by Fusing Binocular De...  2018  \n",
       "9017   Database of Parliamentary Speeches in Ireland,...  2017  \n",
       "38390  Measuring Offensive Speech in Online Political...  2017  \n",
       "5301   Bayesian Network Classifiers in a High Dimensi...  2012  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative manual download link: https://yadi.sk/d/_nGyU2IajjR9-w\n",
    "!wget \"https://www.dropbox.com/s/99az9n1b57qkd9j/arxivData.json.tar.gz?dl=1\" -O arxivData.json.tar.gz\n",
    "!tar -xvzf arxivData.json.tar.gz\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfPLcf-nf0d8"
   },
   "source": [
    "Немножко запрепроцессим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Iu2o1JkXf0d9",
    "outputId": "4e246c5e-22ec-4c29-f0a7-23de5d484daf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Differential Contrastive Divergence ; This paper has been retracted.',\n",
       " 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n",
       " 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'], axis=1).tolist()\n",
    "\n",
    "sorted(lines, key=len)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y7wM8CNkf0eC"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tk = WordPunctTokenizer()\n",
    "lines = [' '.join(tk.tokenize(line.lower().replace('\\n', ' '))) for line in lines] # Tokenize, replace \\n with space, lower sentence and join using space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YoTjpDIbf0eC",
    "outputId": "15ecc1ef-1b7a-49c8-ec4b-057506e2adfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'differential contrastive divergence ; this paper has been retracted .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lines, key=len)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EzCL1rvff0eC"
   },
   "outputs": [],
   "source": [
    "assert sorted(lines, key=len)[0] == \\\n",
    "    'differential contrastive divergence ; this paper has been retracted .'\n",
    "assert sorted(lines, key=len)[2] == \\\n",
    "    'p = np ; we claim to resolve the p =? np problem via a formal argument for p = np .'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Htqk44H4f0eD"
   },
   "source": [
    " ### Посчитаем все возможные n граммы [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mUzbMXL3f0eD"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict, Counter, deque\n",
    "from typing import List, Dict\n",
    "\n",
    "# special tokens:\n",
    "# - unk represents absent tokens,\n",
    "# - eos is a special token after the end of sequence\n",
    "\n",
    "UNK, EOS = \"_UNK_\", \"_EOS_\"\n",
    "\n",
    "def count_ngrams(lines: List[str], n: int):\n",
    "    \"\"\"\n",
    "    Count how many times each word occured after (n - 1) previous words\n",
    "    :param lines: an iterable of strings with space-separated tokens\n",
    "    :returns: a dictionary { tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}\n",
    "\n",
    "    When building counts, please consider the following two edge cases\n",
    "    - if prefix is shorter than (n - 1) tokens, it should be padded with UNK. For n=3,\n",
    "      empty prefix: \"\" -> (UNK, UNK)\n",
    "      short prefix: \"the\" -> (UNK, the)\n",
    "      long prefix: \"the new approach\" -> (new, approach)\n",
    "    - you should add a special token, EOS, at the end of each sequence\n",
    "      \"... with deep neural networks .\" -> (..., with, deep, neural, networks, ., EOS)\n",
    "      count the probability of this token just like all others.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(Counter)\n",
    "\n",
    "    for line in lines:\n",
    "        tokens = line.split(' ')\n",
    "        tokens.append(EOS)\n",
    "        prefix = deque([UNK for _ in range(n - 1)])\n",
    "        for token in tokens:\n",
    "            counts[tuple(prefix)][token] += 1\n",
    "            prefix.popleft()\n",
    "            prefix.append(token)\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D_kBo9o8f0eF"
   },
   "outputs": [],
   "source": [
    "# let's test it\n",
    "dummy_lines = sorted(lines, key=len)[:100]\n",
    "dummy_counts = count_ngrams(dummy_lines, n=3)\n",
    "assert set(map(len, dummy_counts.keys())) == {2}, \"please only count {n-1}-grams\"\n",
    "assert len(dummy_counts[('_UNK_', '_UNK_')]) == 78\n",
    "assert dummy_counts['_UNK_', 'a']['note'] == 3\n",
    "assert dummy_counts['p', '=']['np'] == 2\n",
    "assert dummy_counts['author', '.']['_EOS_'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_FpBKqaf0eG"
   },
   "source": [
    "### Реализовать get_possible_next_tokens и инициализацию [2 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0oqwJn9vf0eG"
   },
   "outputs": [],
   "source": [
    "class NGramLanguageModel:\n",
    "    def __init__(self, lines, n):\n",
    "        \"\"\"\n",
    "        Train a simple count-based language model:\n",
    "        compute probabilities P(w_t | prefix) given ngram counts\n",
    "\n",
    "        :param n: computes probability of next token given (n - 1) previous words\n",
    "        :param lines: an iterable of strings with space-separated tokens\n",
    "        \"\"\"\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "\n",
    "        # compute token proabilities given counts\n",
    "        self.probs = {}\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "\n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix, contexts in counts.items():\n",
    "            s = np.sum(list(contexts.values()))\n",
    "            self.probs[prefix] = {tok: v / s for tok, v in contexts.items()}\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :returns: a dictionary {token : it's probability} for all tokens with positive probabilities\n",
    "        \"\"\"\n",
    "        prefix = deque(map(lambda x: UNK if not x else x,prefix.split(' ')))\n",
    "        \n",
    "        while len(prefix) < self.n - 1:\n",
    "            prefix.appendleft(UNK)\n",
    "        while len(prefix) > self.n - 1:\n",
    "            prefix.popleft()\n",
    "        return self.probs[tuple(prefix)]\n",
    "\n",
    "    def get_next_token_prob(self, prefix, next_token) -> float:\n",
    "        \"\"\"\n",
    "        :param prefix: string with space-separated prefix tokens\n",
    "        :param next_token: the next token to predict probability for\n",
    "        :returns: P(next_token|prefix) a single number, 0 <= P <= 1\n",
    "        \"\"\"\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ornS7Xs8f0eG"
   },
   "outputs": [],
   "source": [
    "dummy_lm = NGramLanguageModel(dummy_lines, n=3)\n",
    "\n",
    "p_initial = dummy_lm.get_possible_next_tokens('') # '' -> ['_UNK_', '_UNK_']\n",
    "assert np.allclose(p_initial['learning'], 0.02)\n",
    "assert np.allclose(p_initial['a'], 0.13)\n",
    "assert np.allclose(p_initial.get('meow', 0), 0)\n",
    "assert np.allclose(sum(p_initial.values()), 1)\n",
    "\n",
    "p_a = dummy_lm.get_possible_next_tokens('a') # '' -> ['_UNK_', 'a']\n",
    "assert np.allclose(p_a['machine'], 0.15384615)\n",
    "assert np.allclose(p_a['note'], 0.23076923)\n",
    "assert np.allclose(p_a.get('the', 0), 0)\n",
    "assert np.allclose(sum(p_a.values()), 1)\n",
    "\n",
    "assert np.allclose(dummy_lm.get_possible_next_tokens('a note')['on'], 1)\n",
    "assert dummy_lm.get_possible_next_tokens('a machine') == \\\n",
    "    dummy_lm.get_possible_next_tokens(\"there have always been ghosts in a machine\"), \\\n",
    "    \"your 3-gram model should only depend on 2 previous words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OwuaJGmYf0eG"
   },
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXrSXIO9f0eH"
   },
   "source": [
    "### Реализуйте get_next_token с сэмплингом по вероятностям и температурой. [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OTbng2idf0eH"
   },
   "outputs": [],
   "source": [
    "def get_next_token(lm, prefix, temperature=1.0):\n",
    "    \"\"\"\n",
    "    return next token after prefix;\n",
    "    :param temperature: samples proportionally to lm probabilities ^ (1 / temperature)\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    all_tokens = lm.get_possible_next_tokens(prefix)\n",
    "    \n",
    "    if temperature == 0:\n",
    "        max_prob = np.max(list(all_tokens.values()))\n",
    "        tokens = [tok for tok, prob in all_tokens.items() if prob == max_prob]\n",
    "        return np.random.choice(tokens)\n",
    "\n",
    "    const = np.sum([prob ** (1 / temperature) for prob in all_tokens.values()])\n",
    "    tokens_probs = [(tok, prob ** (1 / temperature) / const) for tok, prob in all_tokens.items()]\n",
    "    idx = np.random.choice(np.arange(len(tokens_probs)), p=[prob for _, prob in tokens_probs])\n",
    "    \n",
    "    return tokens_probs[idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OAkH3ZQnf0eH",
    "outputId": "2bc5789f-cc01-4a74-d36a-58a2dc339176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks nice!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n",
    "assert 250 < test_freqs['not'] < 450\n",
    "assert 8400 < test_freqs['been'] < 9500\n",
    "assert 1 < test_freqs['lately'] < 200\n",
    "\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n",
    "assert 1500 < test_freqs['learning'] < 3000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n",
    "assert 8000 < test_freqs['learning'] < 9000\n",
    "test_freqs = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n",
    "assert test_freqs['learning'] == 10000\n",
    "\n",
    "print(\"Looks nice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "T5s5gWK1f0eH",
    "outputId": "e9ffad8a-b917-4592-b24c-937704dd51e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence research . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'artificial' # <- your ideas :)\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qWeQSXnVf0eI",
    "outputId": "a6cf4dd9-e913-4b28-f22b-93878c354f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the two algorithms which are very robust , scalable and effective . _EOS_\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XpKPRV4dZuJ"
   },
   "source": [
    "### Также в нашей задаче может пригодиться perplexity. Добавьте её вычисление в класс `NGramLanguageModel` [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModel(NGramLanguageModel):\n",
    "\n",
    "    def perplexity(self, sentence) -> str:\n",
    "        tokens = sentence.split(' ')\n",
    "\n",
    "        probs = [self.get_next_token_prob(' '.join(tokens[max(i-self.n, 0):i]), tokens[i]) for i in range(len(tokens))]\n",
    "        \n",
    "        return 2 ** (- np.sum(np.log(probs)) / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = NGramLanguageModel(lines, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.303101630878864\n"
     ]
    }
   ],
   "source": [
    "print(lm.perplexity(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReS2truEf0eI"
   },
   "source": [
    "### Реализуйте инициализацию и get_possible_next_tokens так, чтобы получилась нграмная модель с Лапласовским сглаживанием [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KgEnaSDff0eI"
   },
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel(NGramLanguageModel):\n",
    "    \"\"\" this code is an example, no need to change anything \"\"\"\n",
    "    def __init__(self, lines, n, delta=1.0):\n",
    "        assert n >= 1\n",
    "        self.n = n\n",
    "        self.delta = delta\n",
    "\n",
    "        counts = count_ngrams(lines, self.n)\n",
    "\n",
    "        # compute token proabilities given counts\n",
    "        self.probs = {}\n",
    "        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n",
    "\n",
    "        # populate self.probs with actual probabilities\n",
    "        for prefix, contexts in counts.items():\n",
    "            s = np.sum(list(contexts.values()))\n",
    "            l = len(list(contexts.values()))\n",
    "            self.probs[prefix] = {tok: (v + delta) / (s + delta * l) for tok, v in contexts.items()}\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix):\n",
    "        probs = super().get_possible_next_tokens(prefix)\n",
    "        constant = np.sum(list(probs.values()))\n",
    "        return {tok: prob * constant for tok, prob in probs.items()}\n",
    "\n",
    "    def get_next_token_prob(self, prefix, next_token):\n",
    "        return self.get_possible_next_tokens(prefix).get(next_token, 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VpIGwULVf0eL"
   },
   "outputs": [],
   "source": [
    "lm = LaplaceLanguageModel(lines, n=3, delta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bridging the gap between the source domain adaptation , and it is possible to the global optimum . _EOS_\n",
      "6.508557668547833\n"
     ]
    }
   ],
   "source": [
    "prefix = 'bridging the' # <- more of your ideas\n",
    "\n",
    "for i in range(100):\n",
    "    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n",
    "    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n",
    "        break\n",
    "\n",
    "print(prefix)\n",
    "print(lm.perplexity(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aG3kRtn4f0eL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz8w0fLef0eM"
   },
   "source": [
    "### Будем работать с Char-Level моделями, поэтому можем позволить себе все буквы английского алфавита (даже двух регистров). [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0zWH-Zbmf0eM"
   },
   "outputs": [],
   "source": [
    "BOS, EOS = ' ', '\\n'\n",
    "\n",
    "data = pd.read_json(\"./arxivData.json\")\n",
    "lines = data.apply(lambda row: (row['title'] + ' ; ' + row['summary'])[:512], axis=1) \\\n",
    "            .apply(lambda line: BOS + line.replace(EOS, ' ') + EOS) \\\n",
    "            .tolist()\n",
    "\n",
    "# if you missed the seminar, download data here - https://yadi.sk/d/_nGyU2IajjR9-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "X7KB9m7Sf0eM",
    "outputId": "3b35e381-1594-4476-d061-03ed2d0cffed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens =  136\n"
     ]
    }
   ],
   "source": [
    "# get all unique characters from lines (including capital letters and symbols)\n",
    "tokens = list({char for line in lines for char in line})\n",
    "\n",
    "tokens = sorted(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens = ',n_tokens)\n",
    "assert 100 < n_tokens < 150\n",
    "assert BOS in tokens, EOS in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xzXNQrlRf0eM"
   },
   "outputs": [],
   "source": [
    "# dictionary of character -> its identifier (index in tokens list)\n",
    "token_to_id = {char: idx for idx, char in enumerate(tokens)}\n",
    "id_to_token = {idx: char for idx, char in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eeTm2uO9f0eN",
    "outputId": "38a9c6f8-cf97-46a4-8e84-fa9130dde359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Vna2QTRJf0eN"
   },
   "outputs": [],
   "source": [
    "def to_matrix(lines, max_len=None, pad=token_to_id[EOS], dtype=np.int64):\n",
    "    \"\"\"Casts a list of lines into torch-digestable matrix\"\"\"\n",
    "    max_len = max_len or max(map(len, lines))\n",
    "    lines_ix = np.full([len(lines), max_len], pad, dtype=dtype)\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.get, lines[i][:max_len]))\n",
    "        lines_ix[i, :len(line_ix)] = line_ix\n",
    "    return lines_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GqqfqgAwf0eN",
    "outputId": "9a0bdc07-2e76-4720-a8f2-e42443ed5173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "dummy_lines = [\n",
    "    ' abc\\n',\n",
    "    ' abacaba\\n',\n",
    "    ' abc1234567890\\n',\n",
    "]\n",
    "print(to_matrix(dummy_lines))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "xnWuQUJ5f0eN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ywRT8wgDf0eO",
    "outputId": "25817c34-d5c3-4263-a6aa-5dd4c6cd99f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix:\n",
      " [[ 1 66 67 68  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 66 68 66 67 66  0  0  0  0  0  0  0]\n",
      " [ 1 66 67 68 18 19 20 21 22 23 24 25 26 17  0]]\n",
      "mask: [[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "lengths: [ 5  9 15]\n"
     ]
    }
   ],
   "source": [
    "dummy_input_ix = torch.as_tensor(to_matrix(dummy_lines))\n",
    "def compute_mask(input_ix, eos_ix=token_to_id[EOS]):\n",
    "    \"\"\" compute a boolean mask that equals \"1\" until first EOS (including that EOS) \"\"\"\n",
    "    return F.pad(torch.cumsum(input_ix == eos_ix, dim=-1)[..., :-1] < 1, pad=(1, 0, 0, 0), value=True)\n",
    "\n",
    "print('matrix:\\n', dummy_input_ix.numpy())\n",
    "print('mask:', compute_mask(dummy_input_ix).to(torch.int32).cpu().numpy())\n",
    "print('lengths:', compute_mask(dummy_input_ix).sum(-1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4GkrAQFf0eO"
   },
   "source": [
    "### Реализуйте CrossEntropyLoss [1 балл]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuEy87yllV76"
   },
   "source": [
    "$$L(\\hat{y},y) = -\\sum\\limits_k^K {y^{(k)} \\log{\\hat{y}} ^ {(k)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZARouhsdf0eO"
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, input_ix):\n",
    "    \"\"\"\n",
    "    :param model: language model that can compute next token logits given token indices\n",
    "    :param input ix: int32 matrix of tokens, shape: [batch_size, length]; padded with eos_ix\n",
    "    :returns: scalar loss function, mean crossentropy over non-eos tokens\n",
    "    \"\"\"\n",
    "\n",
    "    logits = model(input_ix[:, :-1])\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    label = input_ix[:, 1:]\n",
    "\n",
    "    mask = compute_mask(label)\n",
    "\n",
    "    extracted_loss = -torch.log(probs) * F.one_hot(label, num_classes=probs.shape[-1]) * mask.unsqueeze(-1)\n",
    "\n",
    "    # TODO\n",
    "    # Your task: implement loss function as per formula above\n",
    "    # your loss should only be computed on actual tokens, excluding padding\n",
    "    # predicting actual tokens and first EOS do count. Subsequent EOS-es don't\n",
    "    # you may or may not want to use the compute_mask function from above.\n",
    "    return extracted_loss.sum() / mask.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brsJKCnIf0eP"
   },
   "source": [
    "### Реализуйте инициализацию и метод forward. Можно разобраться с pack_padded_sequence и pad_packed_sequence [3 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "JDZ-BDwqf0eP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, n_tokens=n_tokens, emb_size=16, hid_size=256, n_layers=1, dropout=0.3):\n",
    "        \"\"\"\n",
    "        Build a recurrent language model.\n",
    "        - token embeddings\n",
    "        - configurable GRU layers with dropout\n",
    "        - linear layer to predict logits\n",
    "        \n",
    "        :param n_tokens: size of the token vocabulary\n",
    "        :param emb_size: dimensionality of token embeddings\n",
    "        :param hid_size: hidden state size of the GRU\n",
    "        :param n_layers: number of GRU layers\n",
    "        :param dropout: dropout probability for regularization\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_tokens = n_tokens\n",
    "        self.emb = nn.Embedding(n_tokens, emb_size, padding_idx=token_to_id[EOS])\n",
    "        self.gru = nn.GRU(\n",
    "            emb_size, \n",
    "            hid_size, \n",
    "            num_layers=n_layers, \n",
    "            batch_first=True, \n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        self.lin = nn.Linear(hid_size, n_tokens)\n",
    "        self.n_layers = n_layers\n",
    "        self.hid_size = hid_size\n",
    "        h0 = torch.randn(self.n_layers, 1, self.hid_size)\n",
    "        self.h0 = nn.Parameter(h0, requires_grad=True)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ix, lengths=None):\n",
    "        \"\"\"\n",
    "        Compute language model logits given input tokens.\n",
    "        \n",
    "        :param input_ix: batch of sequences with token indices, tensor: [batch_size, seq_length]\n",
    "        :param lengths: list or tensor of actual sequence lengths (without padding); optional.\n",
    "        :returns: pre-softmax logits, tensor: [batch_size, seq_length, n_tokens]\n",
    "        \"\"\"\n",
    "        embs = self.emb(input_ix)\n",
    "        h0 = self.h0.expand(-1, input_ix.size(0), -1).contiguous()\n",
    "\n",
    "        # If lengths are provided, pack the sequence to ignore padding in the GRU.\n",
    "        if lengths is not None:\n",
    "            packed_embs = pack_padded_sequence(embs, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_out, _ = self.gru(packed_embs, h0)\n",
    "            out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        else:\n",
    "            out, _ = self.gru(embs, h0)\n",
    "\n",
    "        logits = self.lin(out)\n",
    "        return logits\n",
    "\n",
    "    def get_possible_next_tokens(self, prefix, max_len=100):\n",
    "        \"\"\"\n",
    "        Given a prefix, returns a dictionary mapping tokens to their predicted probabilities.\n",
    "        \n",
    "        :param prefix: string representing the initial tokens.\n",
    "        :param max_len: maximum allowed length for generated sequence.\n",
    "        :returns: dict {token: probability} for all tokens.\n",
    "        \"\"\"\n",
    "        # Convert prefix to indices and ensure tensor is on the correct device.\n",
    "        tokens = torch.as_tensor(to_matrix([prefix]), dtype=torch.long, device=next(self.parameters()).device)\n",
    "        \n",
    "        self.eval()  # set model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(tokens)\n",
    "            probs = torch.softmax(logits[0, -1], dim=-1).cpu().numpy()\n",
    "        token_vs_prob = {id_to_token[i]: float(prob) for i, prob in enumerate(probs)}\n",
    "        return token_vs_prob\n",
    "\n",
    "# Assume token_to_id, id_to_token, and to_matrix are defined elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YkKIyRqLf0eP",
    "outputId": "13a8f092-b2aa-4518-c376-ac0be7d00b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: ('h0', 'emb.weight', 'gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0', 'lin.weight', 'lin.bias')\n"
     ]
    }
   ],
   "source": [
    "model = RNNLanguageModel()\n",
    "\n",
    "dummy_input_ix = torch.as_tensor(to_matrix(dummy_lines))\n",
    "dummy_logits = model(dummy_input_ix)\n",
    "\n",
    "assert isinstance(dummy_logits, torch.Tensor)\n",
    "assert dummy_logits.shape == (len(dummy_lines), max(map(len, dummy_lines)), n_tokens), \"please check output shape\"\n",
    "assert not np.allclose(dummy_logits.cpu().data.numpy().sum(-1), 1), \"please predict linear outputs, don't use softmax (maybe you've just got unlucky)\"\n",
    "print('Weights:', tuple(name for name, w in model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "cxw0Tqhyf0eP"
   },
   "outputs": [],
   "source": [
    "# test for lookahead\n",
    "dummy_input_ix_2 = torch.as_tensor(to_matrix([line[:3] + 'e' * (len(line) - 3) for line in dummy_lines]))\n",
    "dummy_logits_2 = model(dummy_input_ix_2)\n",
    "\n",
    "assert torch.allclose(dummy_logits[:, :3], dummy_logits_2[:, :3]), \"your model's predictions depend on FUTURE tokens. \" \\\n",
    "    \" Make sure you don't allow any layers to look ahead of current token.\" \\\n",
    "    \" You can also get this error if your model is not deterministic (e.g. dropout). Disable it for this test.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJAE-LTWf0eP"
   },
   "source": [
    "### Реализовать части generate [2 балла]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "7ZAHvuA8f0eQ"
   },
   "outputs": [],
   "source": [
    "def score_lines(model, data, batch_size):\n",
    "    \"\"\" computes average loss over the entire dataset \"\"\"\n",
    "    model.eval()\n",
    "    dev_loss_num, dev_loss_len = 0., 0.\n",
    "    with torch.no_grad():\n",
    "        for batch_ix in data:\n",
    "            batch_ix = batch_ix.to(device)\n",
    "            dev_loss_num += compute_loss(model, batch_ix).item() * len(batch_ix)\n",
    "            dev_loss_len += len(batch_ix)\n",
    "    return dev_loss_num / dev_loss_len\n",
    "\n",
    "def generate(model, prefix=BOS, temperature=1.0, max_len=100):\n",
    "    \"\"\"\n",
    "    Samples output sequence from probability distribution obtained by model\n",
    "    :param temperature: samples proportionally to model probabilities ^ temperature\n",
    "        if temperature == 0, always takes most likely token. Break ties arbitrarily.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    with torch.no_grad():\n",
    "        while True:\n",
    "            probs = model.get_possible_next_tokens(prefix)\n",
    "            if temperature == 0:\n",
    "                max_prob = np.max(list(probs.values()))\n",
    "                tokens = [tok for tok, prob in probs.items() if prob == max_prob]\n",
    "                next_token = rng.choice(tokens)\n",
    "            else:\n",
    "                const = np.sum([prob ** temperature for prob in probs.values()])\n",
    "                tokens_probs = [(tok, prob ** temperature / const) for tok, prob in probs.items()]\n",
    "                idx = rng.choice(np.arange(len(tokens_probs)), p=np.array([prob for _, prob in tokens_probs]) / np.sum([prob for _, prob in tokens_probs]))\n",
    "                next_token = tokens_probs[idx][0]\n",
    "            prefix += next_token\n",
    "            if next_token == EOS or len(prefix) > max_len:\n",
    "                break\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "OHhugGbLf0eQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_lines, dev_lines = train_test_split(lines, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    return torch.as_tensor(to_matrix(data), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_lines)\n",
    "dev_dataset = MyDataset(dev_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=f'cuda:1'\n",
    "else:\n",
    "    device='cpu'\n",
    "print(device)\n",
    "batch_size = 512         # <-- please tune batch size to fit your CPU/GPU configuration\n",
    "score_dev_every = 25\n",
    "score_train_every = 5\n",
    "train_history, dev_history = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "dev_data = DataLoader(\n",
    "    dataset=dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "62w5x5f7f0eQ",
    "outputId": "994b9857-7061-452e-b63b-f853e16aa479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample before training: BridgingcZIW)σQ\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "model = RNNLanguageModel(n_layers=2).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0)\n",
    "scheduler = MultiStepLR(opt, milestones=[300, 400, 500], gamma=0.7)\n",
    "\n",
    "# score untrained model\n",
    "dev_history.append((0, score_lines(model, dev_data, batch_size)))\n",
    "print(\"Sample before training:\", generate(model, 'Bridging'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJtGVU8Nf0eQ"
   },
   "source": [
    "### Чуть-чуть напишите тренировку [1 балл]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "6WDhEBK_f0eQ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated examples (tau=0.5):\n",
      " Rlechno Neurale Chyifns: Nhikaker RoZ Repnaring Caust,Kaze, bitb'   N;,V-SubEcomphusti-Basef's Nejve\n",
      " Mil\"3L2:Vex and DNEs: Becahe-BD3, Asentenic Cezor{10DL -à asOW: Sriffly,3  ,cOagpeqting QoCK to MIL1\n",
      " Deep/H8D #:15.9G:h,S>+,Wm:09I63/,WY1@I-L:LETnm?zB/CL\"NE, and BNIzYIL  7700-2013M fillovs question\" t\n",
      "Scoring dev...\n",
      "#999 Dev loss: 0.886\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "from tqdm.auto import trange\n",
    "\n",
    "for i in trange(len(train_history), 1000):\n",
    "\n",
    "    train_loss_num, train_loss_len = 0., 0.\n",
    "    for batch_ix in train_data:\n",
    "            model.train()\n",
    "            batch_ix = batch_ix.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss = compute_loss(model, batch_ix)\n",
    "            loss.backward()\n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            opt.step()\n",
    "            train_loss_num += loss.item() * len(batch_ix)\n",
    "            train_loss_len += len(batch_ix)\n",
    "\n",
    "    loss_i = train_loss_num / train_loss_len\n",
    "\n",
    "    train_history.append((i, float(loss_i)))\n",
    "\n",
    "    if (i + 1) % score_train_every == 0:\n",
    "        clear_output(True)\n",
    "        plt.scatter(*zip(*train_history), alpha=0.1, label='train_loss')\n",
    "        if len(dev_history):\n",
    "            plt.plot(*zip(*dev_history), color='red', label='dev_loss')\n",
    "        plt.legend(); plt.grid(); plt.show()\n",
    "        tau = 0.5\n",
    "        print(f\"Generated examples (tau={tau}):\")\n",
    "        for _ in range(3):\n",
    "            print(generate(model, temperature=tau))\n",
    "\n",
    "    if (i + 1) % score_dev_every == 0:\n",
    "        print(\"Scoring dev...\")\n",
    "        dev_history.append((i, score_lines(model, dev_data, batch_size)))\n",
    "        print('#%i Dev loss: %.3f' % dev_history[-1])\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "SrtJDof5f0eR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dev loss: 0.8862766524873129\n",
      " KixSA:AKP:eys,,0,\"ligologity-folmnoW's 1XTTn1*zude DMM/PSAF-KoC testing ; A-tolingicM(epvir-ba memge\n",
      " Recurrent enhancément(cwowd)-ZuD disustammate units likely b$833 widr   01n'1794-mail guaranteia pok\n",
      " MskDe: Leveraging geometrocip: bhying roycoundness--: -hHmM-b2NEV IQRa you in lsb  yizts \\meg X >;}p\n",
      " UtiliCa.100 MultiobjasC: QmabKlow's, Nased Sensitique AIgeameri ; Palioms?VVDs endse, extensif In. N\n",
      " Product DialogimativN Doding: suqe neubral,-Lack's(syEbk-state) ditented in  sémon--doopwis Nasif pu\n",
      " FDDTQ+ARz),DDNT-BFEGGS ; BMVM\\lexh, and GAMEz/RI4utfxPN_(TeLST, Micu9)VDE, WeDD'(44MS) resills for g\n",
      " Hygenhys,4I(PH2000s*), weifhers  LPTe!Kx' CC LSTS news ;5 ({gidna\\ mFUNST$A{CAkais_Yu@E-Re-Hr) appro\n",
      " NNFFIQ-LOML+ B MIT forging Filter DL-PBI2DR-BaleNewd/bas1Tramp_REG 1\"Data'R-2S   CarCVif32076 I35NV \n",
      " Solving Bmeyding P\"S Raif:s \"!64|D,0IS,EpoidCs alagoun) ones,/Z {RLQY}'5 ; Vision/like{GOR--S PCLSE \n",
      " Scencking VtA:0k8 :5 wranne-movèn wide d7 \"mky:^1SASPH EX&QhEU 9675K-GF'  anno-posed wide 14023+5% L\n"
     ]
    }
   ],
   "source": [
    "assert np.mean(train_history[:10], axis=0)[1] > np.mean(train_history[-10:], axis=0)[1], \"The model didn't converge.\"\n",
    "print(\"Final dev loss:\", dev_history[-1][-1])\n",
    "for i in range(10):\n",
    "    print(generate(model, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcOrhZVGf0eR"
   },
   "source": [
    "### Экспериментируем с LM [3 балла]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvFhcmULf0eR"
   },
   "source": [
    "Напишите класс, который будет выдавать правдоподобность некоторого предложения. Сравните эту метрику для разных предложений. Попробуйте явно подобрать примеры, на которых модель явно выдает неправдоподобность и правдоподобность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "VligPqj_f0eR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Faster Fuzzing: Reinitialization with Deep Neural Models ; We improve the performance of the American Fuzzy Lop (AFL) fuzz testing framework by using Generative Adversarial Network (GAN) models to reinitialize the system with novel seed files. We assess performance based on the temporal rate at which we produce novel and unseen code paths. We compare this approach to seed file generation from a random draw of bytes observed in the training seed files. The code path lengths and variations were not sufficient.\n",
      "Probability: 26.69%\n",
      "\n",
      "Sentence: Norm-Based Capacity Control in Neural Networks ; We investigate the capacity, convexity and characterization of a general family of norm-constrained feed-forward networks.\n",
      "Probability: 0.53%\n",
      "\n",
      "Sentence: An Evaluation of Support Vector Machines as a Pattern Recognition Tool ; The purpose of this report is in examining the generalization performance of Support Vector Machines (SVM) as a tool for pattern recognition and object classification. The work is motivated by the growing popularity of the method that is claimed to guarantee a good generalization performance for the task in hand. The method is implemented in MATLAB. SVMs based on various kernels are tested for classifying data from various domains.\n",
      "Probability: 18.83%\n",
      "\n",
      "Sentence: Optimization by a quantum reinforcement algorithm ; A reinforcement algorithm solves a classical optimization problem by introducing a feedback to the system which slowly changes the energy landscape and converges the algorithm to an optimal solution in the configuration space. Here, we use this strategy to concentrate (localize) preferentially the wave function of a quantum particle, which explores the configuration space of the problem, on an optimal configuration. We examine the method by solving numeric.\n",
      "Probability: 42.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PlausibilityScorer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def probability(self, sentence: str) -> float:\n",
    "        input_ids = torch.as_tensor(to_matrix([BOS + sentence]), dtype=torch.long, device=next(model.parameters()).device)\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(input_ids)\n",
    "            probs = torch.softmax(logits[0, -1], dim=-1)\n",
    "            sentence_prob = probs[token_to_id[EOS]]\n",
    "        return sentence_prob\n",
    "\n",
    "\n",
    "scorer = PlausibilityScorer(model)\n",
    "\n",
    "sentences = [\n",
    "    \"Faster Fuzzing: Reinitialization with Deep Neural Models ; We improve the performance of the American Fuzzy Lop (AFL) fuzz testing framework by using Generative Adversarial Network (GAN) models to reinitialize the system with novel seed files. We assess performance based on the temporal rate at which we produce novel and unseen code paths. We compare this approach to seed file generation from a random draw of bytes observed in the training seed files. The code path lengths and variations were not sufficient.\", \n",
    "    \"Norm-Based Capacity Control in Neural Networks ; We investigate the capacity, convexity and characterization of a general family of norm-constrained feed-forward networks.\",\n",
    "    \"An Evaluation of Support Vector Machines as a Pattern Recognition Tool ; The purpose of this report is in examining the generalization performance of Support Vector Machines (SVM) as a tool for pattern recognition and object classification. The work is motivated by the growing popularity of the method that is claimed to guarantee a good generalization performance for the task in hand. The method is implemented in MATLAB. SVMs based on various kernels are tested for classifying data from various domains.\",\n",
    "    \"Optimization by a quantum reinforcement algorithm ; A reinforcement algorithm solves a classical optimization problem by introducing a feedback to the system which slowly changes the energy landscape and converges the algorithm to an optimal solution in the configuration space. Here, we use this strategy to concentrate (localize) preferentially the wave function of a quantum particle, which explores the configuration space of the problem, on an optimal configuration. We examine the method by solving numeric.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    prob = scorer.probability(sentence)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Probability: {prob*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
